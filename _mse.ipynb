{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens import HookedTransformer\n",
    "from sparse_autoencoder.loss import normalized_mean_squared_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "from openwebtext import load_owt, sample\n",
    "from pretrained_sae import load_sae\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "seed = 42\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "layer_index = 6\n",
    "location = \"resid_post_mlp\"\n",
    "device = utils.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39949c8f0b04c6491f0d0dcd8b55e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8,013,769 sample texts from data/owt_tokenized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukaemon/miniconda3/envs/topk_sae/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n",
      "Loaded pretrained SAE data/sae/v5_32k_location_resid_post_mlp_layer_6.pt\n",
      "Loaded pretrained SAE data/sae/v5_128k_location_resid_post_mlp_layer_6.pt\n"
     ]
    }
   ],
   "source": [
    "ds = load_owt()\n",
    "gpt2 = HookedTransformer.from_pretrained(\"gpt2\", center_writing_weights=False)\n",
    "\n",
    "sae_32k = load_sae(32, location, layer_index, device)\n",
    "sae_128k = load_sae(128, location, layer_index, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing MSE for 262,144 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:36<00:00,  7.08batch/s, tps=7,811.72]\n"
     ]
    }
   ],
   "source": [
    "n_batch = 256\n",
    "batch_size = 16\n",
    "mse_32k_bin = []\n",
    "mse_128k_bin = []\n",
    "\n",
    "def sae_mse(sae, act, bin):\n",
    "    latent_act, info = sae.encode(act)\n",
    "    recon_act_btd = sae.decode(latent_act, info)\n",
    "    mse = normalized_mean_squared_error(recon_act_btd, act)\n",
    "    bin.append(mse.item())\n",
    "\n",
    "def hook_fn_compute_mse(act_btd, hook):\n",
    "    sae_mse(sae_32k, act_btd, mse_32k_bin)\n",
    "    sae_mse(sae_128k, act_btd, mse_128k_bin)\n",
    "\n",
    "\n",
    "hook_name = utils.get_act_name(\"resid_post\", layer_index)\n",
    "\n",
    "print(f\"start processing MSE for {n_batch * batch_size * 64:,} tokens\")\n",
    "with tqdm(range(n_batch), unit=\"batch\", postfix={\"tps\": 0}) as pbar:\n",
    "    for _ in pbar:\n",
    "        start = time.perf_counter()\n",
    "        \n",
    "        batch = sample(ds, batch_size=batch_size, rng=rng)\n",
    "        gpt2.run_with_hooks(batch, return_type=None, fwd_hooks=[(hook_name, hook_fn_compute_mse)])\n",
    "\n",
    "        delta = time.perf_counter() - start\n",
    "        tok_per_batch = batch_size * 64\n",
    "        tps = tok_per_batch / delta\n",
    "        \n",
    "        pbar.set_postfix({\"tps\": f\"{tps:,.2f}\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13054200427723117, 0.0986246868269518)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mse_32k_bin), np.mean(mse_128k_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topk_sae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
